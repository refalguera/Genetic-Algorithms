{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "mnist_cnn.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWI7ab87lDGd",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm for Tuning CNN Hyperparameters\n",
        "\n",
        "- Neural Network Architeture: CNN -> using keras;-\n",
        "- Dataset: Mnist;\n",
        "- Hyperparameters: Hidden Layers Size, Optimizers and Learning Rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgVL_PkvlDGe",
        "colab_type": "text"
      },
      "source": [
        "### 1. Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdmaltlAlDGe",
        "colab_type": "code",
        "outputId": "dc663b44-576a-46f1-c887-03ccbbec0370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import Keras\n",
        "import keras\n",
        "\n",
        "# Import Mnist dataset\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Network Model  \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "#Import the network optimizers\n",
        "from keras.optimizers import Adam, RMSprop, Adagrad, Adadelta, Adamax, SGD\n",
        "\n",
        "#Import utilities\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from operator import add\n",
        "from functools import reduce\n",
        "from keras import backend as K\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEfKlc6SlDGi",
        "colab_type": "text"
      },
      "source": [
        "### 2. Define Fixed Hyperparameters \n",
        "\n",
        "Initially, we will define 3 hyperparameters with fixed values: number of classes, batch size, and number of epochs. \n",
        "- Number of Classes: Define the total number of classes that the network can classify an image.\n",
        "- Batch Size: The batch size is a number of samples processed before the model is updated.\n",
        "- Epochs: The number of epochs is the number of complete passes through the training dataset.\n",
        "- CallBacks: A callback is an object that can perform actions at various stages of training. In EarlyStopping, the training will stop when the monitored metric has stopped improving, in our case, the network accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_GSsEAmlDGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 10    \n",
        "batch_size = 128\n",
        "n_epochs = 2\n",
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlJYJ2mulDGl",
        "colab_type": "text"
      },
      "source": [
        "### 3. Preparing the Data\n",
        "\n",
        "The second step is to prepare the training and test data. Thereby, to make the netwotk easier to train will normalize the image pixel values from [0, 255] to [0.0, 1.0]. Also, since Keras requeires the third dimension, we will reshape each image from (28, 28) to (n_samples, 28, 28, 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmpwcYxMlDGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data split between train and test sets\n",
        "(X_train, y_train), (X_val, y_val) = mnist.load_data()\n",
        "\n",
        "# Reshape Images data to a tensor of shape. For our 28x28 graysacle images, this would be \n",
        "# (n_samples, 28, 28, 1)\n",
        "\n",
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "n_channels = 1 # we have grayscale images\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], image_height, image_width, n_channels))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], image_height, image_width, n_channels))\n",
        "input_shape = (image_height, image_width, n_channels)\n",
        "\n",
        "# Normalize the images to values between (0.0, 1.0)\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_val = X_val.astype('float32')/255\n",
        "\n",
        "# Since we are using the Crossentropy loss to calculate the difference between the predictions and the labels, it is necessary to convert the labels from a class vector to a binary class matrix.\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_val = to_categorical(y_val, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxCk9bk6lDGo",
        "colab_type": "text"
      },
      "source": [
        "### 4. Building the Model\n",
        "\n",
        "For building the CNN model, since our CNN will be a linear stack of layers, we will work with the Keras's Sequencial Class. Our CNN will be compose of:\n",
        "- 3 Convolutional Layers;\n",
        "- 2 MaxPooling Layers;\n",
        "- 1 Flatten Layer;\n",
        "- 1 Fully Connected Layers;\n",
        "- Ouput Layer (Softmax);\n",
        "\n",
        "In our work, we will try to find the best values for the Hyperparameters Hidden Layers Size, Optimizers and Learning Rate by using a Genetic Algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhZtUsGClDGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(parameters, n_classes, input_shape):\n",
        "    print(parameters)\n",
        "    \n",
        "    #Inicialize the Hyperparamets\n",
        "    optimizer = parameters['optimizer']\n",
        "    learning_rate = parameters['learning_rate']\n",
        "    layer1 = parameters['layer_1']\n",
        "    layer2 = parameters['layer_2']\n",
        "    layer3 = parameters['layer_3']\n",
        "    dropout = parameters['Dropout']\n",
        "\n",
        "    # Create the Model\n",
        "    model = Sequential()\n",
        "    # Add Convolutional layers\n",
        "    model.add(Conv2D(filters=2**layer1, kernel_size=(3,3), activation='relu', padding='same',\n",
        "                     input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    if layer2 > 0:\n",
        "      model.add(Conv2D(filters=2**layer2, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "      model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    if layer3 > 0:\n",
        "      model.add(Conv2D(filters=2**layer3, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "      model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "\n",
        "    model.add(Dropout(dropout))   \n",
        "    model.add(Flatten())\n",
        "    # Densely connected layers\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    # Output layer\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "    # Define the network optimizer function based on the optimizer hyperparameters defined by the GA.\n",
        "    if optimizer == 'Adam':\n",
        "        opt = Adam(learning_rate)\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate)\n",
        "    elif optimizer == 'Adagrad':\n",
        "        opt = Adagrad(learning_rate)\n",
        "    elif optimizer == 'Adadelta':\n",
        "        opt = Adadelta(learning_rate)\n",
        "    elif optimizer == 'Adamax':\n",
        "        opt = Adamax(learning_rate)\n",
        "    elif optimizer == 'SGD':\n",
        "        opt = SGD(learning_rate)\n",
        "    \n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju7mCKSWlDGr",
        "colab_type": "text"
      },
      "source": [
        "We need a class Network that we can use to create a network with random parameters and train the network. Moreover, it should be able to retrieve the accuracy of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCZ_N3gIlDGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network():\n",
        "    def __init__(self, parameter_space=None):\n",
        "        self.accuracy = 0.\n",
        "        self.parameter_space = parameter_space\n",
        "        self.network_parameters = {}\n",
        "        \n",
        "    def set_random_parameters(self):\n",
        "        for parameter in self.parameter_space:\n",
        "            self.network_parameters[parameter] = random.choice(self.parameter_space[parameter])\n",
        "            \n",
        "    def create_network(self, network):\n",
        "        self.network_parameters = network\n",
        "    \n",
        "    def train(self):\n",
        "        model = create_model(self.network_parameters, n_classes, input_shape)\n",
        "        history = model.fit(X_train, y_train,\n",
        "        batch_size=batch_size, epochs=n_epochs,\n",
        "        verbose=0, validation_data=(X_val, y_val),\n",
        "        callbacks=callbacks)\n",
        "        self.accuracy = max(history.history['val_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyxUL_XdlDGt",
        "colab_type": "text"
      },
      "source": [
        "### 5. Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olm3APWxlDGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Genetic_Algorithm():\n",
        "    def __init__(self, parameter_space, retain=0.3, random_select=0.1, mutate_prob=0.25):\n",
        "        self.mutate_prob = mutate_prob\n",
        "        self.random_select = random_select\n",
        "        self.retain = retain\n",
        "        self.parameter_space = parameter_space\n",
        "    \n",
        "    # Create Initial Population\n",
        "    def create_population(self, count):\n",
        "        population = []\n",
        "        for _ in range(0, count):\n",
        "                 network = Network(self.parameter_space)\n",
        "                 network.set_random_parameters()\n",
        "                 population.append(network)\n",
        "        return population\n",
        "                 \n",
        "    # Get fitness from each individual. The fitness function will be the accuray of the network\n",
        "    def get_fitness(network):\n",
        "        return network.accuracy\n",
        "   \n",
        "    def get_grade(self, population):\n",
        "        total = reduce(add, (get_fitness(network)\n",
        "        for network in population))\n",
        "        return float(total) / len(population)\n",
        "               \n",
        "    # Crossover to generate a new population\n",
        "    def breed(self, mother, father):\n",
        "        children = []\n",
        "        for _ in range(2):\n",
        "            child = {}\n",
        "            for param in self.parameter_space:\n",
        "                child[param] = random.choice(\n",
        "                    [mother.network[param],\n",
        "                    father.network[param]]\n",
        "                )\n",
        "            network = Network(self.nn_param_choices)\n",
        "            network.create_set(child)\n",
        "            if self.mutate_chance > random.random():\n",
        "                network = self.mutate(network)\n",
        "            children.append(network)\n",
        "        return children\n",
        "    \n",
        "    # Mutate indiviuals to create a more diversified population  \n",
        "    def mutate(self, network):\n",
        "        mutation = random.choice(list\n",
        "        (self.parameter_space.keys()))\n",
        "        network.network[mutation] = random.choice(self.parameter_space[mutation])\n",
        "        return network        \n",
        "    \n",
        "    # Evolve the population to generate a new population\n",
        "    def evolve(self, pop):\n",
        "        for net in pop:\n",
        "          print(net)\n",
        "          \n",
        "        graded = [(self.get_fitness(network),\n",
        "        network) for network in pop]\n",
        "        graded = [x[1] for x in sorted(graded,\n",
        "        key=lambda x: x[0], reverse=True)]\n",
        "        retain_length = int(len(graded)*self.retain)\n",
        "        \n",
        "        parents = graded[:retain_length]\n",
        "        \n",
        "        for individual in graded[retain_length:]:\n",
        "            if self.random_select > random.random():\n",
        "                parents.append(individual)\n",
        "        \n",
        "        parents_length = len(parents)\n",
        "        desired_length = len(pop) - parents_length\n",
        "        children = []\n",
        "\n",
        "        while len(children) < desired_length:\n",
        "            male = random.randint(0,\n",
        "            parents_length-1)\n",
        "            female = random.randint(0,\n",
        "            parents_length-1)\n",
        "                 \n",
        "            if male != female:\n",
        "                male = parents[male]\n",
        "                female = parents[female]\n",
        "                children_new = self.breed(male,female)\n",
        "                \n",
        "                for child_new in children_new:\n",
        "                    if len(children) < desired_length:\n",
        "                        children.append(child_new)\n",
        "                \n",
        "        parents.extend(children)\n",
        "                 \n",
        "        return parents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07qxaUQplDGw",
        "colab_type": "text"
      },
      "source": [
        "We will retrieve the average accuracy across a population:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lucYiZBYlDGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_population_accuracy(population):\n",
        "    total_accuracy = 0\n",
        "    for network in population:\n",
        "        total_accuracy += network.accuracy\n",
        "    \n",
        "    return total_accuracy / len(population)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DISXfSEMlDGz",
        "colab_type": "text"
      },
      "source": [
        "### 6. Set Parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPCjyY8mlDGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_generations = 2\n",
        "population_size = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIp5KhAClDG2",
        "colab_type": "text"
      },
      "source": [
        "We now set the remaining hyperparameters space that we want to explore: Hidden Layers Size, Optimizers and Learning Rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErhV9paalDG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameter_space = {\n",
        "    'optimizer': ['Adam', 'rmsprop', 'Adagrad', 'Adadelta', 'Adamax', 'SGD'],\n",
        "    'layer_1': [0, 1, 2, 3, 4, 5, 6, 7],\n",
        "    'layer_2': [0, 1, 2, 3, 4, 5, 6, 7],\n",
        "    'layer_3': [0, 1, 2, 3, 4, 5, 6, 7],\n",
        "    'Dropout': [0, 0.25, 0.5],\n",
        "    'learning_rate': [0.1, 0.01, 0.001, 0.0001]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXn7E0kOlDG6",
        "colab_type": "text"
      },
      "source": [
        "We will create the initial population:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DTVF9hGlDG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GA = Genetic_Algorithm(parameter_space)\n",
        "population = GA.create_population(population_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wmfOpxRlDG9",
        "colab_type": "code",
        "outputId": "bd052e4f-abd4-40f0-ff6e-7560057d8e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for i in range(n_generations):\n",
        "    print('Generation {}'.format(i))\n",
        "    \n",
        "    for network in population:\n",
        "        network.train()\n",
        "\n",
        "    average_accuracy = get_population_accuracy(population)\n",
        "    print('Average accuracy: {:.2f}'.\n",
        "    format(average_accuracy))\n",
        "    \n",
        "    # Evolve\n",
        "    if i < n_generations - 1:\n",
        "        s = GA.evolve(population)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation 0\n",
            "{'optimizer': 'rmsprop', 'layer_1': 4, 'layer_2': 1, 'layer_3': 1, 'Dropout': 0.5, 'learning_rate': 0.0001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8gTT2f1lDG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}